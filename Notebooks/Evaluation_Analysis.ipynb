{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../eval_results_20250512_184623/test_predictions_detailed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Primary_Element\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Composition   Actual   Predicted      Error  Absolute_Error  \\\n",
      "0  Sr0.98Ga0.02  1026.95  1028.74800  -1.798096        1.798096   \n",
      "1  Sr0.57Ga0.43  1001.17  1006.73895  -5.568970        5.568970   \n",
      "2  Ga0.22Ba0.78   717.58   769.79940 -52.219360       52.219360   \n",
      "3  Ge0.87Ga0.13  1166.02  1262.69900 -96.678955       96.678955   \n",
      "4  Mg0.58Cu0.42   844.14   871.76953 -27.629517       27.629517   \n",
      "\n",
      "   Percentage_Error  Ag_fraction  Al_fraction  Ba_fraction  Bi_fraction  ...  \\\n",
      "0          0.175091          0.0          0.0         0.00          0.0  ...   \n",
      "1          0.556246          0.0          0.0         0.00          0.0  ...   \n",
      "2          7.277148          0.0          0.0         0.78          0.0  ...   \n",
      "3          8.291363          0.0          0.0         0.00          0.0  ...   \n",
      "4          3.273096          0.0          0.0         0.00          0.0  ...   \n",
      "\n",
      "   In_fraction  Li_fraction  Mg_fraction  Na_fraction  Pb_fraction  \\\n",
      "0          0.0          0.0         0.00          0.0          0.0   \n",
      "1          0.0          0.0         0.00          0.0          0.0   \n",
      "2          0.0          0.0         0.00          0.0          0.0   \n",
      "3          0.0          0.0         0.00          0.0          0.0   \n",
      "4          0.0          0.0         0.58          0.0          0.0   \n",
      "\n",
      "   Sb_fraction  Sn_fraction  Sr_fraction  Zn_fraction  n_elements  \n",
      "0          0.0          0.0         0.98          0.0           2  \n",
      "1          0.0          0.0         0.57          0.0           2  \n",
      "2          0.0          0.0         0.00          0.0           2  \n",
      "3          0.0          0.0         0.00          0.0           2  \n",
      "4          0.0          0.0         0.00          0.0           2  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_composition(self, composition: str) -> list[tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Parse composition string to extract elements and their fractions\n",
    "    Example: \"Al0.19Mg0.81\" -> [(\"Al\", 0.19), (\"Mg\", 0.81)]\n",
    "    \n",
    "    Args:\n",
    "        composition: String representation of the composition (e.g., \"Al0.19Mg0.81\")\n",
    "        \n",
    "    Returns:\n",
    "        List of tuples with elements and their normalized fractions\n",
    "    \"\"\"\n",
    "    pattern = r'([A-Z][a-z]*)([0-9]*\\.?[0-9]*)'\n",
    "    matches = re.findall(pattern, composition)\n",
    "\n",
    "    elements_fractions = []\n",
    "    for element, fraction in matches:\n",
    "        # Handle empty fraction (e.g., \"Fe\" instead of \"Fe1.0\")\n",
    "        if fraction == \"\":\n",
    "            fraction = \"1\"\n",
    "        frac = float(fraction)\n",
    "        if frac > 1:\n",
    "            frac = frac / 100.0\n",
    "        elements_fractions.append((element, frac))\n",
    "    \n",
    "    # Normalize fractions to ensure they sum to 1\n",
    "    total = sum(frac for _, frac in elements_fractions)\n",
    "    if total != 1.0:\n",
    "        elements_fractions = [(element, frac/total) for element, frac in elements_fractions]\n",
    "    \n",
    "    # Pad with empty elements if needed (for fixed-length representation)\n",
    "    while len(elements_fractions) < 4:\n",
    "        elements_fractions.append((\"\", 0.0))\n",
    "    return elements_fractions\n",
    "\n",
    "def analyze_element_count_impact(self):\n",
    "    \"\"\"\n",
    "    Analyze how the number of elements in an alloy affects prediction accuracy\n",
    "    \"\"\"\n",
    "    if self.results_df is None:\n",
    "        self.create_results_dataframe()\n",
    "    \n",
    "    # Group by number of elements\n",
    "    element_count_analysis = self.results_df.groupby('n_elements').agg({\n",
    "        'Absolute_Error': ['mean', 'median', 'std', 'min', 'max', 'count'],\n",
    "        'Percentage_Error': ['mean', 'median']\n",
    "    })\n",
    "    \n",
    "    # Save to CSV\n",
    "    element_count_analysis.to_csv(os.path.join(self.save_dir, 'element_count_analysis.csv'))\n",
    "    \n",
    "    # Create visualization\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Plot 1: Mean error by element count\n",
    "    ax1 = plt.subplot(2, 1, 1)\n",
    "    bars = ax1.bar(element_count_analysis.index, element_count_analysis[('Absolute_Error', 'mean')])\n",
    "    \n",
    "    # Add count labels\n",
    "    for bar, count in zip(bars, element_count_analysis[('Absolute_Error', 'count')]):\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f'n={int(count)}', ha='center', va='bottom', rotation=0)\n",
    "    \n",
    "    ax1.set_xlabel('Number of Elements in Composition')\n",
    "    ax1.set_ylabel('Mean Absolute Error')\n",
    "    ax1.set_title('Mean Prediction Error by Number of Elements')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Box plot of errors by element count\n",
    "    ax2 = plt.subplot(2, 1, 2)\n",
    "    \n",
    "    element_counts = sorted(self.results_df['n_elements'].unique())\n",
    "    data_for_boxplot = [self.results_df[self.results_df['n_elements'] == count]['Absolute_Error'] \n",
    "                        for count in element_counts]\n",
    "    \n",
    "    ax2.boxplot(data_for_boxplot, labels=[f'{count} elements' for count in element_counts])\n",
    "    ax2.set_ylabel('Absolute Error')\n",
    "    ax2.set_title('Error Distribution by Number of Elements')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(self.save_dir, 'element_count_analysis.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"\\nImpact of Element Count on Prediction Error:\")\n",
    "    print(element_count_analysis)\n",
    "    \n",
    "    return element_count_analysis\n",
    "\n",
    "def analyze_entropy_effect(self):\n",
    "    \"\"\"\n",
    "    Analyze how compositional entropy affects prediction accuracy\n",
    "    Entropy is higher when elements are more evenly distributed\n",
    "    \"\"\"\n",
    "    if self.results_df is None:\n",
    "        self.create_results_dataframe()\n",
    "    \n",
    "    # Calculate compositional entropy for each alloy\n",
    "    entropies = []\n",
    "    \n",
    "    for idx, row in self.results_df.iterrows():\n",
    "        composition = row['Composition']\n",
    "        elements_fractions = self.parse_composition(composition)\n",
    "        \n",
    "        # Calculate Shannon entropy: -sum(p * log(p))\n",
    "        entropy = 0\n",
    "        for _, frac in elements_fractions:\n",
    "            if frac > 0:\n",
    "                entropy -= frac * np.log(frac)\n",
    "        \n",
    "        entropies.append(entropy)\n",
    "    \n",
    "    # Add entropy to results dataframe\n",
    "    self.results_df['Compositional_Entropy'] = entropies\n",
    "    \n",
    "    # Create entropy bands for analysis\n",
    "    self.results_df['Entropy_Band'] = pd.cut(\n",
    "        self.results_df['Compositional_Entropy'], \n",
    "        bins=5, \n",
    "        labels=['Very Low', 'Low', 'Medium', 'High', 'Very High']\n",
    "    )\n",
    "    \n",
    "    # Analyze error by entropy band\n",
    "    entropy_analysis = self.results_df.groupby('Entropy_Band').agg({\n",
    "        'Absolute_Error': ['mean', 'median', 'std', 'count'],\n",
    "        'Percentage_Error': ['mean', 'median']\n",
    "    })\n",
    "    \n",
    "    # Save to CSV\n",
    "    entropy_analysis.to_csv(os.path.join(self.save_dir, 'entropy_analysis.csv'))\n",
    "    \n",
    "    # Visualize relationship between entropy and error\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    # Plot 1: Scatter plot of entropy vs error\n",
    "    ax1 = plt.subplot(2, 2, 1)\n",
    "    scatter = ax1.scatter(\n",
    "        self.results_df['Compositional_Entropy'], \n",
    "        self.results_df['Absolute_Error'],\n",
    "        alpha=0.6, \n",
    "        c=self.results_df['n_elements'],\n",
    "        cmap='viridis',\n",
    "        s=50\n",
    "    )\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(self.results_df['Compositional_Entropy'], self.results_df['Absolute_Error'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    x_range = np.linspace(self.results_df['Compositional_Entropy'].min(), \n",
    "                          self.results_df['Compositional_Entropy'].max(), 100)\n",
    "    ax1.plot(x_range, p(x_range), \"r--\", linewidth=2)\n",
    "    \n",
    "    # Add correlation coefficient\n",
    "    corr = np.corrcoef(self.results_df['Compositional_Entropy'], self.results_df['Absolute_Error'])[0, 1]\n",
    "    ax1.text(0.05, 0.95, f\"r = {corr:.2f}\", transform=ax1.transAxes, \n",
    "             fontsize=12, va='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
    "    \n",
    "    ax1.set_xlabel('Compositional Entropy', fontsize=12)\n",
    "    ax1.set_ylabel('Absolute Error', fontsize=12)\n",
    "    ax1.set_title('Prediction Error vs Compositional Entropy', fontsize=14)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add colorbar for number of elements\n",
    "    cbar = plt.colorbar(scatter, ax=ax1)\n",
    "    cbar.set_label('Number of Elements', fontsize=12)\n",
    "    \n",
    "    # Plot 2: Bar chart of mean error by entropy band\n",
    "    ax2 = plt.subplot(2, 2, 2)\n",
    "    bars = ax2.bar(entropy_analysis.index, entropy_analysis[('Absolute_Error', 'mean')])\n",
    "    \n",
    "    # Add count labels\n",
    "    for bar, count in zip(bars, entropy_analysis[('Absolute_Error', 'count')]):\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f'n={int(count)}', ha='center', va='bottom', rotation=0)\n",
    "    \n",
    "    ax2.set_xlabel('Entropy Band', fontsize=12)\n",
    "    ax2.set_ylabel('Mean Absolute Error', fontsize=12)\n",
    "    ax2.set_title('Mean Error by Compositional Entropy', fontsize=14)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Box plot of errors by entropy band\n",
    "    ax3 = plt.subplot(2, 2, 3)\n",
    "    sns.boxplot(x='Entropy_Band', y='Absolute_Error', data=self.results_df, ax=ax3)\n",
    "    ax3.set_xlabel('Entropy Band', fontsize=12)\n",
    "    ax3.set_ylabel('Absolute Error', fontsize=12)\n",
    "    ax3.set_title('Error Distribution by Compositional Entropy', fontsize=14)\n",
    "    \n",
    "    # Plot 4: Entropy vs percentage error\n",
    "    ax4 = plt.subplot(2, 2, 4)\n",
    "    scatter = ax4.scatter(\n",
    "        self.results_df['Compositional_Entropy'], \n",
    "        self.results_df['Percentage_Error'],\n",
    "        alpha=0.6, \n",
    "        c=self.results_df['Actual'],\n",
    "        cmap='plasma',\n",
    "        s=50\n",
    "    )\n",
    "    \n",
    "    z = np.polyfit(self.results_df['Compositional_Entropy'], self.results_df['Percentage_Error'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax4.plot(x_range, p(x_range), \"r--\", linewidth=2)\n",
    "    \n",
    "    corr = np.corrcoef(self.results_df['Compositional_Entropy'], self.results_df['Percentage_Error'])[0, 1]\n",
    "    ax4.text(0.05, 0.95, f\"r = {corr:.2f}\", transform=ax4.transAxes, \n",
    "             fontsize=12, va='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
    "    \n",
    "    ax4.set_xlabel('Compositional Entropy', fontsize=12)\n",
    "    ax4.set_ylabel('Percentage Error (%)', fontsize=12)\n",
    "    ax4.set_title('Percentage Error vs Compositional Entropy', fontsize=14)\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    cbar = plt.colorbar(scatter, ax=ax4)\n",
    "    cbar.set_label('Actual Temperature (K)', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(self.save_dir, 'entropy_analysis.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"\\nImpact of Compositional Entropy on Prediction Error:\")\n",
    "    print(entropy_analysis)\n",
    "    \n",
    "    return entropy_analysis\n",
    "\n",
    "def analyze_elemental_similarity(self):\n",
    "    \"\"\"\n",
    "    Analyze if compositions with similar elements but different ratios \n",
    "    have consistent prediction errors\n",
    "    \"\"\"\n",
    "    if self.results_df is None:\n",
    "        self.create_results_dataframe()\n",
    "    \n",
    "    # Find all unique elements in the dataset\n",
    "    element_columns = [col for col in self.results_df.columns if col.endswith('_fraction')]\n",
    "    elements = [col.split('_')[0] for col in element_columns]\n",
    "    elements = [e for e in elements if e]  # Remove empty strings\n",
    "    \n",
    "    # Get element sets (combinations of elements used in compositions)\n",
    "    element_sets = []\n",
    "    element_set_to_idx = {}\n",
    "    \n",
    "    for idx, row in self.results_df.iterrows():\n",
    "        # Get elements present in this composition\n",
    "        present_elements = set()\n",
    "        for element in elements:\n",
    "            if row[f'{element}_fraction'] > 0:\n",
    "                present_elements.add(element)\n",
    "        \n",
    "        present_elements = tuple(sorted(present_elements))\n",
    "        \n",
    "        if present_elements:\n",
    "            if present_elements not in element_set_to_idx:\n",
    "                element_set_to_idx[present_elements] = len(element_sets)\n",
    "                element_sets.append(present_elements)\n",
    "    \n",
    "    # Add element set index to dataframe\n",
    "    self.results_df['Element_Set'] = -1\n",
    "    for idx, row in self.results_df.iterrows():\n",
    "        present_elements = tuple(sorted([\n",
    "            element for element in elements \n",
    "            if row[f'{element}_fraction'] > 0\n",
    "        ]))\n",
    "        \n",
    "        if present_elements in element_set_to_idx:\n",
    "            self.results_df.at[idx, 'Element_Set'] = element_set_to_idx[present_elements]\n",
    "    \n",
    "    # Find element sets with at least 3 compositions for meaningful analysis\n",
    "    element_set_counts = self.results_df['Element_Set'].value_counts()\n",
    "    common_element_sets = element_set_counts[element_set_counts >= 3].index.tolist()\n",
    "    \n",
    "    if not common_element_sets:\n",
    "        print(\"No element sets with at least 3 compositions found. Skipping elemental similarity analysis.\")\n",
    "        return None\n",
    "    \n",
    "    # Create consolidated dataframe for analysis\n",
    "    element_set_data = []\n",
    "    \n",
    "    for set_idx in common_element_sets:\n",
    "        set_compositions = self.results_df[self.results_df['Element_Set'] == set_idx]\n",
    "        element_names = element_sets[set_idx]\n",
    "        \n",
    "        element_set_data.append({\n",
    "            'Element_Set': '-'.join(element_names),\n",
    "            'Count': len(set_compositions),\n",
    "            'Mean_Error': set_compositions['Absolute_Error'].mean(),\n",
    "            'Std_Error': set_compositions['Absolute_Error'].std(),\n",
    "            'Mean_Pct_Error': set_compositions['Percentage_Error'].mean(),\n",
    "            'Min_Temp': set_compositions['Actual'].min(),\n",
    "            'Max_Temp': set_compositions['Actual'].max(),\n",
    "            'Temp_Range': set_compositions['Actual'].max() - set_compositions['Actual'].min()\n",
    "        })\n",
    "    \n",
    "    element_set_df = pd.DataFrame(element_set_data)\n",
    "    element_set_df = element_set_df.sort_values('Count', ascending=False)\n",
    "    \n",
    "    # Save to CSV\n",
    "    element_set_df.to_csv(os.path.join(self.save_dir, 'element_set_analysis.csv'), index=False)\n",
    "    \n",
    "    # Visualize element set analysis\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Plot 1: Error by element set\n",
    "    ax1 = plt.subplot(2, 1, 1)\n",
    "    \n",
    "    # Limit to top 15 most common sets for readability\n",
    "    top_sets = element_set_df.head(15)\n",
    "    \n",
    "    bars = ax1.bar(top_sets['Element_Set'], top_sets['Mean_Error'])\n",
    "    \n",
    "    # Add error bars\n",
    "    ax1.errorbar(\n",
    "        top_sets['Element_Set'], \n",
    "        top_sets['Mean_Error'],\n",
    "        yerr=top_sets['Std_Error'],\n",
    "        fmt='none', \n",
    "        ecolor='black', \n",
    "        capsize=5\n",
    "    )\n",
    "    \n",
    "    # Add count labels\n",
    "    for bar, count in zip(bars, top_sets['Count']):\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 2,\n",
    "                f'n={int(count)}', ha='center', va='bottom', rotation=0)\n",
    "    \n",
    "    ax1.set_xlabel('Element Combination', fontsize=12)\n",
    "    ax1.set_ylabel('Mean Absolute Error', fontsize=12)\n",
    "    ax1.set_title('Prediction Error by Element Combination', fontsize=14)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot 2: Detailed analysis of top element sets\n",
    "    ax2 = plt.subplot(2, 1, 2)\n",
    "    \n",
    "    # Get top 5 most common element sets for detailed analysis\n",
    "    top_5_sets = element_set_df.head(5)['Element_Set'].tolist()\n",
    "    \n",
    "    # Create list of compositions for each set\n",
    "    detailed_data = []\n",
    "    \n",
    "    for set_name in top_5_sets:\n",
    "        element_names = set_name.split('-')\n",
    "        set_idx = element_set_to_idx[tuple(element_names)]\n",
    "        \n",
    "        set_compositions = self.results_df[self.results_df['Element_Set'] == set_idx]\n",
    "        \n",
    "        for idx, row in set_compositions.iterrows():\n",
    "            # Get the ratio of the first element to second element (for binary systems)\n",
    "            if len(element_names) == 2:\n",
    "                ratio = row[f'{element_names[0]}_fraction'] / row[f'{element_names[1]}_fraction'] if row[f'{element_names[1]}_fraction'] > 0 else 0\n",
    "            else:\n",
    "                ratio = 0\n",
    "                \n",
    "            detailed_data.append({\n",
    "                'Element_Set': set_name,\n",
    "                'Composition': row['Composition'],\n",
    "                'Actual': row['Actual'],\n",
    "                'Predicted': row['Predicted'],\n",
    "                'Error': row['Absolute_Error'],\n",
    "                'Ratio': ratio\n",
    "            })\n",
    "    \n",
    "    detailed_df = pd.DataFrame(detailed_data)\n",
    "    \n",
    "    # For binary systems, plot error vs. element ratio\n",
    "    binary_sets = [s for s in top_5_sets if len(s.split('-')) == 2]\n",
    "    \n",
    "    if binary_sets:\n",
    "        for set_name in binary_sets:\n",
    "            set_data = detailed_df[detailed_df['Element_Set'] == set_name]\n",
    "            ax2.scatter(\n",
    "                set_data['Ratio'], \n",
    "                set_data['Error'],\n",
    "                label=set_name,\n",
    "                s=50,\n",
    "                alpha=0.7\n",
    "            )\n",
    "        \n",
    "        ax2.set_xlabel('Element Ratio (First/Second)', fontsize=12)\n",
    "        ax2.set_ylabel('Absolute Error', fontsize=12)\n",
    "        ax2.set_title('Error vs Element Ratio for Binary Systems', fontsize=14)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.legend()\n",
    "    else:\n",
    "        # If no binary systems, create a different visualization\n",
    "        sns.boxplot(x='Element_Set', y='Error', data=detailed_df, ax=ax2)\n",
    "        ax2.set_xlabel('Element Combination', fontsize=12)\n",
    "        ax2.set_ylabel('Absolute Error', fontsize=12)\n",
    "        ax2.set_title('Error Distribution by Element Combination', fontsize=14)\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(self.save_dir, 'element_set_analysis.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Create scatter plots for top binary systems\n",
    "    if binary_sets:\n",
    "        for set_name in binary_sets[:3]:  # Limit to top 3 for brevity\n",
    "            plt.figure(figsize=(14, 7))\n",
    "            \n",
    "            set_data = detailed_df[detailed_df['Element_Set'] == set_name]\n",
    "            element_names = set_name.split('-')\n",
    "            \n",
    "            # Plot 1: Error vs first element fraction\n",
    "            ax1 = plt.subplot(1, 2, 1)\n",
    "            scatter = ax1.scatter(\n",
    "                [row[f'{element_names[0]}_fraction'] for _, row in set_data.iterrows()],\n",
    "                set_data['Error'],\n",
    "                c=set_data['Actual'],\n",
    "                cmap='viridis',\n",
    "                s=70,\n",
    "                alpha=0.8\n",
    "            )\n",
    "            \n",
    "            ax1.set_xlabel(f'{element_names[0]} Fraction', fontsize=12)\n",
    "            ax1.set_ylabel('Absolute Error', fontsize=12)\n",
    "            ax1.set_title(f'Error vs {element_names[0]} Content for {set_name}', fontsize=14)\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "            \n",
    "            cbar = plt.colorbar(scatter, ax=ax1)\n",
    "            cbar.set_label('Actual Temperature (K)', fontsize=12)\n",
    "            \n",
    "            # Plot 2: Actual vs Predicted for this system\n",
    "            ax2 = plt.subplot(1, 2, 2)\n",
    "            fractions = [row[f'{element_names[0]}_fraction'] for _, row in set_data.iterrows()]\n",
    "            \n",
    "            scatter = ax2.scatter(\n",
    "                set_data['Actual'],\n",
    "                set_data['Predicted'],\n",
    "                c=fractions,\n",
    "                cmap='plasma',\n",
    "                s=70,\n",
    "                alpha=0.8\n",
    "            )\n",
    "            \n",
    "            # Add perfect prediction line\n",
    "            min_val = min(set_data['Actual'].min(), set_data['Predicted'].min())\n",
    "            max_val = max(set_data['Actual'].max(), set_data['Predicted'].max())\n",
    "            ax2.plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.7)\n",
    "            \n",
    "            ax2.set_xlabel('Actual Temperature (K)', fontsize=12)\n",
    "            ax2.set_ylabel('Predicted Temperature (K)', fontsize=12)\n",
    "            ax2.set_title(f'Predicted vs Actual for {set_name}', fontsize=14)\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "            \n",
    "            cbar = plt.colorbar(scatter, ax=ax2)\n",
    "            cbar.set_label(f'{element_names[0]} Fraction', fontsize=12)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(self.save_dir, f'binary_analysis_{set_name}.png'), dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "    \n",
    "    print(\"\\nElement Set Analysis (Top 10):\")\n",
    "    print(element_set_df.head(10))\n",
    "    \n",
    "    return element_set_df\n",
    "\n",
    "def run_full_evaluation(self):\n",
    "    \"\"\"Run complete evaluation pipeline with enhanced element analysis\"\"\"\n",
    "    print(\"Starting model evaluation...\")\n",
    "    \n",
    "    # Get predictions\n",
    "    self.predict()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    self.calculate_metrics()\n",
    "    \n",
    "    # Create results dataframe\n",
    "    self.create_results_dataframe()\n",
    "    \n",
    "    # Basic plots\n",
    "    print(\"Creating basic evaluation plots...\")\n",
    "    self.plot_basic_evaluation()\n",
    "    self.plot_composition_analysis()\n",
    "    \n",
    "    # Enhanced element analysis\n",
    "    print(\"Performing enhanced element analysis...\")\n",
    "    \n",
    "    # Analysis of element count impact\n",
    "    print(\"Analyzing impact of element count...\")\n",
    "    self.analyze_element_count_impact()\n",
    "    \n",
    "    # Analysis of compositional entropy\n",
    "    print(\"Analyzing effect of compositional entropy...\")\n",
    "    self.analyze_entropy_effect()\n",
    "    \n",
    "    # Analysis of elemental similarity\n",
    "    print(\"Analyzing elemental similarity patterns...\")\n",
    "    self.analyze_elemental_similarity()\n",
    "    \n",
    "    # Save results\n",
    "    print(\"Saving results...\")\n",
    "    self.save_results()\n",
    "    \n",
    "    # Additional information to console\n",
    "    print(\"\\nTop 10 Worst Predictions:\")\n",
    "    print(\"Composition | Primary Element | Actual | Predicted | Error\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    worst_10 = self.results_df.nlargest(10, 'Absolute_Error')\n",
    "    for _, row in worst_10.iterrows():\n",
    "        print(f\"{row['Composition']:<20} | {row['Primary_Element']:<15} | {row['Actual']:6.2f} | {row['Predicted']:9.2f} | {row['Absolute_Error']:5.2f}\")\n",
    "    \n",
    "    return self.results_df, self.summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
