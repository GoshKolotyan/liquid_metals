## Model Architecture v2

```
Input Tensor [batch_size, 6, 5] â† FIXED: 6 positions (5 elements + 1 feature row)
     â”‚    
     â–¼    
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   
â”‚  Linear Embedding  â”‚  Transform raw features to embedding dimension      
â”‚  [5 â†’ d_model=128] â”‚  â† FIXED: Reduced from 512 to 128     
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        
     â”‚    
     â–¼    
Fixed Role Embedding with Permutation:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Positions 0-4: SHUFFLED elements â†’ Element Role     â”‚ â† PERMUTE THESE
â”‚                 Any element can be in any position  â”‚
â”‚                 Role = "I am an element"            â”‚
â”‚ Position 5:     Mixture properties â†’ Feature Role   â”‚ â† KEEP FIXED
â”‚                 Always in position 5                â”‚
â”‚                 Role = "I am mixture features"      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚    
     â–¼  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  â”‚         ğŸš¨ CRITICAL FIX 1:           â”‚
     â”‚  â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   
â”Œâ”€â”€â”€â”€â–¼â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    ACTUALLY ADD EMBEDDINGS!      â”‚ 
â”‚  x = x + role   â”‚  â”‚  x = x + role_embeddings         â”‚
â”‚   _embeddings   â”‚  â”‚  (Was commented out before)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚    
     â–¼              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚         ğŸš¨ CRITICAL FIX 2:           â”‚
â”‚ Create Attentionâ”‚ â”‚      ATTENTION MASKING               â”‚
â”‚     Mask        â”‚ â”‚  mask = [True, True, False, ...]     â”‚
â”‚ [batch,seq_len] â”‚ â”‚  (True=real data, False=padding)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚              
     â–¼   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  
     â”‚   â”‚      Transformer Encoder Block      â”‚  â† FIXED: 2 layers (was 3)
     â”‚   â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  
     â”‚   â”‚ â”‚    Multi-Head Attention (4Ã—)    â”‚ â”‚  â† FIXED: 4 heads (was 8)
     â”‚   â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”      â”‚ â”‚  
     â”œâ”€â”€â–ºâ”‚ â”‚  â”‚Head1â”‚  â”‚Head2â”‚  â”‚Head3â”‚ ...  â”‚ â”‚  Specialized heads for    
     â”‚   â”‚ â”‚  â”‚(MP) â”‚  â”‚(AR) â”‚  â”‚(EN) â”‚      â”‚ â”‚  different properties   
     â”‚   â”‚ â”‚  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜      â”‚ â”‚  
     â”‚   â”‚ â”‚             â”‚                   â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚   â”‚ â”‚    ğŸ” WITH ATTENTION MASK       â”‚ â”‚  â”‚  mask prevents model â”‚
     â”‚   â”‚ â”‚    (ignores padding tokens)     â”‚ â”‚  â”‚  from learning from  â”‚
     â”‚   â”‚ â”‚             â”‚                   â”‚ â”‚  â”‚  padding positions   â”‚
     â”‚   â”‚ â”‚     Concat and Project          â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚   â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  
     â”‚   â”‚               â”‚                     â”‚  
     â”‚   â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  
     â”‚   â”‚ â”‚   + Residual Connection       â”‚   â”‚  
     â”‚   â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  
     â”‚   â”‚               â”‚                     â”‚  
     â”‚   â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  
     â”‚   â”‚ â”‚    Layer Normalization        â”‚   â”‚       
     â”‚   â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  
     â”‚   â”‚               â”‚                     â”‚  
     â”‚   â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  
     â”‚   â”‚ â”‚  Feed-Forward Network         â”‚   â”‚  â† Element-wise transformations  
     â”‚   â”‚ â”‚  [128 â†’ 512 â†’ 128]            â”‚   â”‚     with dropout=0.4
     â”‚   â”‚ â”‚  + Dropout(0.4)               â”‚   â”‚  â† FIXED: Increased dropout
     â”‚   â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  
     â”‚   â”‚               â”‚                     â”‚  
     â”‚   â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  
     â”‚   â”‚ â”‚   + Residual Connection       â”‚   â”‚  
     â”‚   â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  
     â”‚   â”‚               â”‚                     â”‚  
     â”‚   â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  
     â”‚   â”‚ â”‚    Layer Normalization        â”‚   â”‚       
     â”‚   â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  
     â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  
     â”‚                   â”‚    
     â”‚                   â–¼         
     â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  
     â””â”€â”€â–ºâ”‚  Stack 2 Layers (was 3)             â”‚  â† FIXED: Reduced complexity
         â”‚  ğŸ”§ WITH WEIGHT DECAY = 0.01        â”‚  â† FIXED: Added L2 regularization
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  
                         â”‚    
                         â–¼    
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  
             â”‚   ğŸ¯ Global Pooling   â”‚  Combine information across    
             â”‚   (Mean over valid    â”‚  ONLY non-masked positions
             â”‚    positions only)    â”‚  (ignores padding)
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  
                         â”‚    
                         â–¼    
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  
             â”‚   Regression Head     â”‚  Project to final prediction   
             â”‚  [128 â†’ 128 â†’ 1]      â”‚  â† 2 layers with dropout
             â”‚  + Dropout(0.4)       â”‚  
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  
                         â”‚    
                         â–¼    
                  Predicted Melting Point    
                     [batch_size] 
```

This architecture implements a transformer-based model for predicting melting points from chemical composition data. The model processes input tensors representing chemical mixtures through specialized attention mechanisms and outputs melting point predictions.


**Without Permutation (Current - BROKEN)**
`
Training Examples:
AlFeNi: Position 0=Al, Position 1=Fe, Position 2=Ni
CuZnSn: Position 0=Cu, Position 1=Zn, Position 2=Sn

Model Learns: "Position 0 behaves like Al, Position 1 behaves like Fe"

Pentanary Test: AlFeCuNiCr
Model Thinks: Position 0=Al (correct), Position 1=Fe (correct), 
              Position 2=Cu (WRONG! expects Ni), Position 3=? (panic!)
`


**With Permutation (Fixed - CORRECT)**
`
Training Examples:
AlFeNi: Position 0=Fe, Position 1=Al, Position 2=Ni  (shuffled)
CuZnSn: Position 1=Sn, Position 2=Cu, Position 0=Zn  (shuffled)
AlFeNi: Position 2=Al, Position 0=Ni, Position 1=Fe  (shuffled again)

Model Learns: "Any position can contain any element, focus on element properties"

Pentanary Test: AlFeCuNiCr (any order)
Model Thinks: "I see Al properties, Fe properties, Cu properties, etc. regardless of position"

`